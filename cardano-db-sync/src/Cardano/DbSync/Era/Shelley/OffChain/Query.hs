{-# LANGUAGE TypeApplications #-}
{-# LANGUAGE NoImplicitPrelude #-}

module Cardano.DbSync.Era.Shelley.OffChain.Query (
  aquireOffChainPoolData,
) where

import Cardano.Db (
  EntityField (OffChainPoolDataPmrId, OffChainPoolFetchErrorFetchTime, OffChainPoolFetchErrorId, OffChainPoolFetchErrorPmrId, OffChainPoolFetchErrorPoolId, OffChainPoolFetchErrorRetryCount, PoolHashId, PoolMetadataRefHash, PoolMetadataRefId, PoolMetadataRefPoolId, PoolMetadataRefUrl),
  OffChainPoolData,
  OffChainPoolFetchError,
  OffChainPoolFetchErrorId,
  PoolHash,
  PoolHashId,
  PoolMetaHash (PoolMetaHash),
  PoolMetadataRef,
  PoolMetadataRefId,
  PoolUrl,
 )
import Cardano.DbSync.Era.Shelley.OffChain.FetchQueue (newRetry, retryAgain)
import Cardano.DbSync.Types (OffChainPoolFetchRetry (..))
import Cardano.Prelude hiding (from, groupBy, on, retry)
import Data.Time (UTCTime)
import Data.Time.Clock.POSIX (POSIXTime)
import qualified Data.Time.Clock.POSIX as Time
import Database.Esqueleto.Experimental (
  SqlBackend,
  SqlExpr,
  Value (..),
  ValueList,
  desc,
  from,
  groupBy,
  in_,
  innerJoin,
  just,
  max_,
  notExists,
  on,
  orderBy,
  select,
  subList_select,
  table,
  where_,
  (:&) ((:&)),
  (==.),
  (^.),
 )
import System.Random.Shuffle (shuffleM)

{- HLINT ignore "Fuse on/on" -}

aquireOffChainPoolData :: MonadIO m => POSIXTime -> Int -> ReaderT SqlBackend m [OffChainPoolFetchRetry]
aquireOffChainPoolData now maxCount = do
  -- Results from the query are shuffles so we don't continuously get the same entries.
  xs <- queryNewPoolFetch now
  if length xs >= maxCount
    then take maxCount <$> liftIO (shuffleM xs)
    else do
      ys <- queryOffChainPoolFetchRetry (Time.posixSecondsToUTCTime now)
      take maxCount . (xs ++) <$> liftIO (shuffleM ys)

-- Get pool fetch data for new pools (ie pools that had OffChainPoolData entry and no
-- OffChainPoolFetchError).
queryNewPoolFetch :: MonadIO m => POSIXTime -> ReaderT SqlBackend m [OffChainPoolFetchRetry]
queryNewPoolFetch now = do
  res <- select $ do
    (ph :& pmr) <-
      from
        $ table @PoolHash
          `innerJoin` table @PoolMetadataRef
        `on` (\(ph :& pmr) -> ph ^. PoolHashId ==. pmr ^. PoolMetadataRefPoolId)
    where_ (just (pmr ^. PoolMetadataRefId) `in_` latestRefs)
    where_ (notExists $ from (table @OffChainPoolData) >>= \pod -> where_ (pod ^. OffChainPoolDataPmrId ==. pmr ^. PoolMetadataRefId))
    where_ (notExists $ from (table @OffChainPoolFetchError) >>= \pofe -> where_ (pofe ^. OffChainPoolFetchErrorPmrId ==. pmr ^. PoolMetadataRefId))
    pure
      ( ph ^. PoolHashId
      , pmr ^. PoolMetadataRefId
      , pmr ^. PoolMetadataRefUrl
      , pmr ^. PoolMetadataRefHash
      )
  pure $ map convert res
  where
    -- This assumes that the autogenerated `id` field is a reliable proxy for time, ie, higher
    -- `id` was added later. This is a valid assumption because the primary keys are
    -- monotonically increasing and never reused.
    latestRefs :: SqlExpr (ValueList (Maybe PoolMetadataRefId))
    latestRefs =
      subList_select $ do
        pmr <- from $ table @PoolMetadataRef
        groupBy (pmr ^. PoolMetadataRefPoolId)
        pure $ max_ (pmr ^. PoolMetadataRefId)

    convert ::
      (Value PoolHashId, Value PoolMetadataRefId, Value PoolUrl, Value ByteString) ->
      OffChainPoolFetchRetry
    convert (Value phId, Value pmrId, Value url, Value pmh) =
      OffChainPoolFetchRetry
        { opfrPoolHashId = phId
        , opfrReferenceId = pmrId
        , opfrPoolUrl = url
        , opfrPoolMDHash = Just $ PoolMetaHash pmh
        , opfrRetry = newRetry now
        }

-- Get pool fetch data for pools that have previously errored.
queryOffChainPoolFetchRetry :: MonadIO m => UTCTime -> ReaderT SqlBackend m [OffChainPoolFetchRetry]
queryOffChainPoolFetchRetry _now = do
  res <- select $ do
    (ph :& pmr :& pofe) <-
      from
        $ table @PoolHash
          `innerJoin` table @PoolMetadataRef
        `on` (\(ph :& pmr) -> ph ^. PoolHashId ==. pmr ^. PoolMetadataRefPoolId)
          `innerJoin` table @OffChainPoolFetchError
        `on` (\(_ph :& pmr :& pofe) -> pofe ^. OffChainPoolFetchErrorPmrId ==. pmr ^. PoolMetadataRefId)
    where_ (just (pofe ^. OffChainPoolFetchErrorId) `in_` latestRefs)
    where_ (notExists $ from (table @OffChainPoolData) >>= \pod -> where_ (pod ^. OffChainPoolDataPmrId ==. pofe ^. OffChainPoolFetchErrorPmrId))
    orderBy [desc (pofe ^. OffChainPoolFetchErrorFetchTime)]
    pure
      ( pofe ^. OffChainPoolFetchErrorFetchTime
      , pofe ^. OffChainPoolFetchErrorPmrId
      , pmr ^. PoolMetadataRefUrl
      , pmr ^. PoolMetadataRefHash
      , ph ^. PoolHashId
      , pofe ^. OffChainPoolFetchErrorRetryCount
      )
  pure $ map convert res
  where
    -- This assumes that the autogenerated `id` fiels is a reliable proxy for time, ie, higher
    -- `id` was added later. This is a valid assumption because the primary keys are
    -- monotonically increasing and never reused.
    latestRefs :: SqlExpr (ValueList (Maybe OffChainPoolFetchErrorId))
    latestRefs =
      subList_select $ do
        pofe <- from (table @OffChainPoolFetchError)
        groupBy (pofe ^. OffChainPoolFetchErrorPoolId)
        pure $ max_ (pofe ^. OffChainPoolFetchErrorId)

    convert ::
      (Value UTCTime, Value PoolMetadataRefId, Value PoolUrl, Value ByteString, Value PoolHashId, Value Word) ->
      OffChainPoolFetchRetry
    convert (Value time, Value pmrId, Value url, Value pmh, Value phId, Value rCount) =
      OffChainPoolFetchRetry
        { opfrPoolHashId = phId
        , opfrReferenceId = pmrId
        , opfrPoolUrl = url
        , opfrPoolMDHash = Just $ PoolMetaHash pmh
        , opfrRetry = retryAgain (Time.utcTimeToPOSIXSeconds time) rCount
        }
